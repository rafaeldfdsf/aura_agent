"""
Speech-to-Text (escuta e transcriÃ§Ã£o).

Responsabilidades:
- Captar Ã¡udio do microfone
- Detetar inÃ­cio e fim da fala
- Filtrar ruÃ­do / TV
- Transcrever com Whisper

Este ficheiro concentra TODA a lÃ³gica de escuta.
"""

import sounddevice as sd
import numpy as np
import queue
import time
import tempfile
import os
from scipy.io.wavfile import write
from faster_whisper import WhisperModel

from config import SAMPLE_RATE, STOP_TTS
from audio.signals import beep

# Modelo Whisper carregado uma Ãºnica vez
whisper = WhisperModel("small", device="cpu", compute_type="int8")

def listen(voice_threshold):
    global STOP_TTS

    print("ğŸ¤ Fala agora...")

    q = queue.Queue()

    def callback(indata, frames, time_info, status):
        if status:
            print(status)
        q.put(indata.copy())

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32",
        blocksize=512,
        callback=callback
    ):
        audio_chunks = []
        pre_speech_buffer = []
        MAX_PRE_CHUNKS = 6   # ~200â€“300 ms de Ã¡udio antes da fala

        silence_start = None
        speech_started = False
        voice_start_time = None
        speech_start_time = None

        while True:
            try:
                chunk = q.get(timeout=0.05)
            except queue.Empty:
                continue

            volume = np.linalg.norm(chunk) * 10

            # ğŸ” Guardar Ã¡udio antes da fala (buffer)
            if not speech_started:
                pre_speech_buffer.append(chunk)
                if len(pre_speech_buffer) > MAX_PRE_CHUNKS:
                    pre_speech_buffer.pop(0)

            # ğŸ”‡ Antes da fala comeÃ§ar
            if not speech_started:
                if volume > voice_threshold:
                    if voice_start_time is None:
                        voice_start_time = time.time()
                    elif time.time() - voice_start_time > 0.3:
                        STOP_TTS = True
                        speech_started = True
                        speech_start_time = time.time()
                        silence_start = None
                        beep()

                        # ğŸ‘‡ junta o buffer + chunk atual
                        audio_chunks.extend(pre_speech_buffer)
                        pre_speech_buffer.clear()
                        audio_chunks.append(chunk)
                else:
                    voice_start_time = None
                    continue

            # ğŸ”Š Depois da fala comeÃ§ar
            else:
                audio_chunks.append(chunk)

                if volume > voice_threshold:
                    silence_start = None
                else:
                    if silence_start is None:
                        silence_start = time.time()
                    elif time.time() - silence_start > 0.7:
                        break

            # â›‘ï¸ Limite de seguranÃ§a (6s reais de fala)
            if speech_started and speech_start_time:
                if time.time() - speech_start_time > 6:
                    break

    if not audio_chunks:
        print("âŒ NÃ£o percebi.")
        return None

    audio = np.concatenate(audio_chunks).squeeze()

    # ğŸ”§ NormalizaÃ§Ã£o segura (nÃ£o amplifica ruÃ­do)
    max_val = np.max(np.abs(audio))
    if max_val > 0:
        audio = audio / max(max_val, 0.3)

    # ğŸš€ TranscriÃ§Ã£o
    segments, _ = whisper.transcribe(
        audio,
        language="pt",
        beam_size=3,
        initial_prompt="comandos curtos e claros em portuguÃªs europeu",
        vad_filter=False
    )

    text = "".join(seg.text for seg in segments).strip()

    if not text:
        print("âŒ NÃ£o percebi.")
        return None

    print(f"Tu: {text}")
    return text

def calibrate_noise(duration=1.5):
    """
    Mede o ruÃ­do ambiente para definir um limiar de voz dinÃ¢mico.

    Deve ser chamado UMA vez no arranque.
    """
    print("ğŸ”‡ A calibrar ruÃ­do ambiente... fica em silÃªncio")

    samples = []
    start = time.time()

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32"
    ) as stream:
        while time.time() - start < duration:
            chunk, _ = stream.read(1024)
            volume = np.linalg.norm(chunk) * 10
            samples.append(volume)

    noise_level = np.mean(samples)
    threshold = noise_level * 1.5  # margem de seguranÃ§a

    print(f"ğŸ”ˆ RuÃ­do base: {noise_level:.4f}")
    print(f"ğŸšï¸ Limiar de voz: {threshold:.4f}")

    return threshold