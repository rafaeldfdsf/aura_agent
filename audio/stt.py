"""
Speech-to-Text (escuta e transcri√ß√£o).

Responsabilidades:
- Captar √°udio do microfone
- Detetar in√≠cio e fim da fala
- Filtrar ru√≠do / TV
- Transcrever com Whisper

Este ficheiro concentra TODA a l√≥gica de escuta.
"""

import sounddevice as sd
import numpy as np
import queue
import time
import tempfile
import os
from scipy.io.wavfile import write
from faster_whisper import WhisperModel

from config import SAMPLE_RATE, STOP_TTS
from audio.signals import beep

# Modelo Whisper carregado uma √∫nica vez
whisper = WhisperModel("small", device="cpu", compute_type="int8")

def listen(voice_threshold):
    global STOP_TTS

    print("üé§ Fala agora...")

    q = queue.Queue()

    def callback(indata, frames, time_info, status):
        if status:
            print(status)
        q.put(indata.copy())

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32",
        blocksize=512,
        callback=callback
    ):
        audio_chunks = []
        silence_start = None
        start_time = time.time()
        speech_started = False
        voice_start_time = None

        while True:
            try:
                chunk = q.get(timeout=0.05)
            except queue.Empty:
                continue

            volume = np.linalg.norm(chunk) * 10

            # üîá Antes da fala come√ßar
            if not speech_started:
                if volume > voice_threshold:
                    if voice_start_time is None:
                        voice_start_time = time.time()
                    elif time.time() - voice_start_time > 0.2:  # 200 ms cont√≠nuos
                        STOP_TTS = True          # üî¥ barge-in
                        speech_started = True
                        silence_start = None
                        beep()                  # üîî feedback
                        audio_chunks.append(chunk)
                else:
                    voice_start_time = None
                    continue

            # üîä Depois da fala come√ßar
            else:
                audio_chunks.append(chunk)

                if volume > voice_threshold:
                    silence_start = None
                else:
                    if silence_start is None:
                        silence_start = time.time()
                    elif time.time() - silence_start > 0.25:
                        break

            # ‚õëÔ∏è limite de seguran√ßa
            if speech_started and time.time() - start_time > 6:
                break

    if not audio_chunks:
        print("‚ùå N√£o percebi.")
        return None

    audio = np.concatenate(audio_chunks).squeeze()

    # normalizar
    audio = audio / np.max(np.abs(audio))
    audio_int16 = np.int16(audio * 32767)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
        wav_path = f.name
        write(wav_path, SAMPLE_RATE, audio_int16)

    segments, _ = whisper.transcribe(
        wav_path,
        language="pt",
        beam_size=5,
        vad_filter=True
    )

    os.remove(wav_path)

    text = "".join(seg.text for seg in segments).strip()

    if not text:
        print("‚ùå N√£o percebi.")
        return None

    print(f"Tu: {text}")
    return text

def calibrate_noise(duration=1.5):
    """
    Mede o ru√≠do ambiente para definir um limiar de voz din√¢mico.

    Deve ser chamado UMA vez no arranque.
    """
    print("üîá A calibrar ru√≠do ambiente... fica em sil√™ncio")

    samples = []
    start = time.time()

    with sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32"
    ) as stream:
        while time.time() - start < duration:
            chunk, _ = stream.read(1024)
            volume = np.linalg.norm(chunk) * 10
            samples.append(volume)

    noise_level = np.mean(samples)
    threshold = noise_level * 1.5  # margem de seguran√ßa

    print(f"üîà Ru√≠do base: {noise_level:.4f}")
    print(f"üéöÔ∏è Limiar de voz: {threshold:.4f}")

    return threshold